{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PYTHON FOR ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual contribution:\n",
    "1) P Sri Vaishno - Gaussian Naive Bayes algorithm and Logistic regression algorithm\n",
    "\n",
    "2) B Manjunath - KNN algorithm\n",
    "\n",
    "3) K V Sai Krishna - Linear Discriminant analysis (LDA) and Model analysis \n",
    "\n",
    "4) P Shankar - Support Vector Machine algorithm (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funtion to classify data for better understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataClassification(dataset):\n",
    "    C = dataset.iloc[:, 10]\n",
    "    B = []\n",
    "    M = []\n",
    "    \n",
    "    for i in range(0, len(C)):\n",
    "        if C[i] == 2:\n",
    "            B.append(\"B\")\n",
    "            l1 = len(B)\n",
    "        \n",
    "        elif C[i] == 4:\n",
    "            M.append(\"M\")\n",
    "            l2 = len(M)\n",
    "    test_patients = dataset.shape[0]\n",
    "    \n",
    "    a = str(\"The data consists of \" + str(test_patients) + \" different diagnosis in which \" + str(l1) + \" are Benign and \" + \n",
    "            str(l2) + \" are Malignant\")\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to split the dataset into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingDataset(dataset, splitRatio):\n",
    "    \n",
    "    total_data = dataset.shape[0]\n",
    "    train_data = dataset.iloc[0:(int(splitRatio*total_data)), 1:11]\n",
    "    d = pd.DataFrame(train_data)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testingData(dataset, splitRatio):\n",
    "    \n",
    "    total_data = dataset.shape[0]\n",
    "    test_data = dataset.iloc[int(total_data - total_data*(1 - splitRatio)):total_data, 1:11]\n",
    "    d1 = pd.DataFrame(test_data)\n",
    "    return d1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to understand the how the split happened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataDivision(data1, data2):\n",
    "    \n",
    "    lt1 = len(data1)\n",
    "    lt2 = len(data2)\n",
    "    b = str(\"The data is divided into \" + str(lt1) + \" training data samples and \" + str(lt2) + \" testing data samples\") \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testdataclassification(test_data):\n",
    "    \n",
    "    Bdata, Mdata =  (test_data['Class'].value_counts())\n",
    "    testshape = test_data.shape[0]\n",
    "    \n",
    "    l1 = str(\"The testing data consists of \" + str(testshape) + \" different diagnosis in which \" + str(Bdata) + \n",
    "          \" are Benign and \" + str(Mdata) + \" are Malignant\")\n",
    "    return l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sigmoid function to reduce all the features values in the range (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SigmoidFunction(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to optimize the parameters by calculating the gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Optimize(dataset, classLabel, LearningRate,No_Of_iterations):\n",
    "    \n",
    "    size = dataset.shape[0]\n",
    "    weights = np.zeros(dataset.shape[1]) \n",
    "    bias = 0\n",
    "\n",
    "    # gradient descent\n",
    "    for i in range(No_Of_iterations):\n",
    "        # approximate y with linear combination of weights and x, plus bias\n",
    "        sigma = SigmoidFunction(np.dot(dataset, weights) + bias)\n",
    "\n",
    "        # compute gradients\n",
    "        dw = (1 / size) * np.dot(dataset.T, (sigma - classLabel))\n",
    "        db = (1 / size) * np.sum(sigma - classLabel)\n",
    "        # update parameters\n",
    "        weights -= LearningRate * dw\n",
    "        bias -= LearningRate * db\n",
    "    \n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to predict the class labels for the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_data, weights, bias):\n",
    "    \n",
    "    y_predicted_class = []\n",
    "    # Testing the data\n",
    "    for i in range(0, 9):\n",
    "        pred = SigmoidFunction(np.dot(test_data.iloc[:, i], weights[i]) + bias)\n",
    "    for i in pred:\n",
    "        # The decision boundary\n",
    "        if i < 0.9965361244452257:\n",
    "            y_predicted_class.append(2)\n",
    "        else:\n",
    "            y_predicted_class.append(4)\n",
    "    \n",
    "    return y_predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to evaluate the model performance using different metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classification_report(testData, y_predicted):\n",
    "    \n",
    "   #Intialize the true positives, false positives, true negatives and the false negatives\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "\n",
    "    # Iterate through the p and q lists comparing the predicted labels with the actual ones and computing \n",
    "    # the TP, TN, FP and FN\n",
    "    for i in range(0, len(testData.index)):\n",
    "        if (y_predicted[i] == 2  and testData.iloc[i,9] == 2):\n",
    "            TP += 1\n",
    "        elif (y_predicted[i] == 4 and testData.iloc[i,9] == 4):\n",
    "            TN += 1\n",
    "        elif (y_predicted[i] == 4 and testData.iloc[i,9] == 2):   \n",
    "            FN += 1\n",
    "        elif (y_predicted[i] == 2 and testData.iloc[i,9] == 4):\n",
    "            FP += 1\n",
    "    \n",
    "    # Accuracy is the measure of many correct predictions the model made        \n",
    "    A = (TP + TN)/(TP + TN + FP + FN) * 100.0\n",
    "    \n",
    "    # precision expresses the proportion of the data points our model says was relevant actually were relevant.\n",
    "    P1 = (TP)/(TP + FP) * 100.0\n",
    "    P2 = (TN)/(TN + FN) * 100.0\n",
    "    \n",
    "    # Recall expresses the ability to find all relevant instances in a dataset\n",
    "    R1 = (TP)/(TP + FN) * 100.0\n",
    "    R2 = (TN)/(TN + FP) * 100.0\n",
    "    \n",
    "    # Harmonic mean of recall and precision \n",
    "    F1 = (2*P1*R1)/(R1 + P1)\n",
    "    F2 = (2*P2*R2)/(P2 + R2)\n",
    "    \n",
    "    # A matrix to represent all types of predictions \n",
    "    CM = np.array([[TP, FP],[FN, TN]])\n",
    "    \n",
    "    return A, P1, P2, R1, R2, F1, F2, CM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # Reading the data file and converting it into a dataframe\n",
    "    data = pd.read_excel(r\"C:\\Users\\sriva\\OneDrive\\Desktop\\Python_for_ML_project_dataset\\breast-cancer-wisconsin.xlsx\")\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Giving the constants\n",
    "    LearningRate = 0.001\n",
    "    No_Of_iterations = 1000\n",
    "    splitRatio = 0.75\n",
    "    \n",
    "    # Processing the data\n",
    "    m = dataClassification(data)\n",
    "    df1 = trainingDataset(df, splitRatio)\n",
    "    df2 = testingData(df, splitRatio)\n",
    "    l = DataDivision(df1, df2)\n",
    "    t = testdataclassification(df2)\n",
    "    \n",
    "    # Parameter calculation\n",
    "    weights, bias = Optimize(df1.iloc[:, 0:9], df1.iloc[:,9], LearningRate, No_Of_iterations)\n",
    "    \n",
    "    # Predictions\n",
    "    prediction_class = predict(df2, weights, bias)\n",
    "    \n",
    "    # Model evaluation\n",
    "    Acc, PrecisionB, PrecisionM, RecallB, RecallM, F1_scoreB, F1_scoreM, cm = Classification_report(df2, prediction_class)\n",
    "    \n",
    "    print(m)\n",
    "    print(l)\n",
    "    print(t)\n",
    "    print(\"\\n\" + \"The Accuracy of the Logistic Regression model is: \"+ str(Acc) + \"%\")\n",
    "    print(\"\\n\" + \"The Precision of the Logistic Regression model is: \"+ str((PrecisionB + PrecisionM)/2) + \"%\")\n",
    "    print(\"\\n\" + \"The Recall of the Logistic Regression model is: \"+ str((RecallB + RecallM)/2) + \"%\")\n",
    "    print(\"\\n\" + \"The F1 score of the Logistic Regression model is: \"+ str((F1_scoreB + F1_scoreM)/2) + \"%\")\n",
    "    print(\"\\n\" + \"The Confusion matrix of the Logistic Regression model is: \" + \"\\n\" + str(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data consists of 699 different diagnosis in which 458 are Benign and 241 are Malignant\n",
      "The data is divided into 524 training data samples and 175 testing data samples\n",
      "The testing data consists of 175 different diagnosis in which 137 are Benign and 38 are Malignant\n",
      "\n",
      "The Accuracy of the Logistic Regression model is: 84.57142857142857%\n",
      "\n",
      "The Precision of the Logistic Regression model is: 82.10188933873144%\n",
      "\n",
      "The Recall of the Logistic Regression model is: 68.27698809066462%\n",
      "\n",
      "The F1 score of the Logistic Regression model is: 71.708280941261%\n",
      "\n",
      "The Confusion matrix of the Logistic Regression model is: \n",
      "[[133  23]\n",
      " [  4  15]]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# starting time\n",
    "start = time.time()\n",
    "\n",
    "main()\n",
    "\n",
    "# stoping time\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The runtime of the Logistic Regression model is 0.6323411464691162 sec\n"
     ]
    }
   ],
   "source": [
    "# Print the runtime\n",
    "print(f\"The runtime of the Logistic Regression model is {end - start}\" + \" sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
