{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASSUMPTION:\n",
    "All the features in the given dataset are independent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funtion to classify data for better understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataClassification(dataset):\n",
    "    \n",
    "    # To get the no of observations or datapoints in the given data\n",
    "    C = dataset.iloc[:, 10]\n",
    "    B = []\n",
    "    M = []\n",
    "     \n",
    "    # For every class label \"2\" this loop will append \"B\" to an empty list and for every class label \"4\" it will append \"M\"    \n",
    "    for i in range(0, len(C)):\n",
    "        if C[i] == 2:\n",
    "            B.append(\"B\")\n",
    "            l1 = len(B)\n",
    "        \n",
    "        elif C[i] == 4:\n",
    "            M.append(\"M\")\n",
    "            l2 = len(M)\n",
    "    test_patients = dataset.shape[0]\n",
    "    \n",
    "    # To print our basic understanding of the dataset \n",
    "    a = str(\"The data consists of \" + str(test_patients) + \" different diagnosis in which \" + str(l1) \n",
    "            + \" are Benign and \" + str(l2) + \" are Malignant\")\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to split the dataset into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingDataset(dataset, splitRatio):\n",
    "    \n",
    "    total_data = dataset.shape[0]\n",
    "    \n",
    "    # Splitting the data into two groups for training and testing and this data is for training\n",
    "    # Also removing the sample code number feature as it has no affect on class labels\n",
    "    train_data = dataset.iloc[0:(int(splitRatio*total_data)), 1:11]\n",
    "    \n",
    "    # Converting the data into a dataframe\n",
    "    d = pd.DataFrame(train_data)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testingData(dataset, splitRatio):\n",
    "    \n",
    "    total_data = dataset.shape[0]\n",
    "    \n",
    "    # This data is for testing\n",
    "    # Also removing the sample code number feature as it has no affect on class labels\n",
    "    test_data = dataset.iloc[int(total_data - total_data*(1 - splitRatio)):total_data, 1:11]\n",
    "    \n",
    "    # Converting the data into dataframe\n",
    "    d1 = pd.DataFrame(test_data)\n",
    "    return d1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to understand the how the split happened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataDivision(data1, data2):\n",
    "     \n",
    "    # To analyze the how the data is splitted \n",
    "    lt1 = len(data1)\n",
    "    lt2 = len(data2)\n",
    "    \n",
    "    # To print our basic understanding of the splitting process of the data \n",
    "    b = str(\"The data is divided into \" + str(lt1) + \" training data samples and \" + str(lt2) + \" testing data samples\") \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testdataclassification(test_data):\n",
    "    \n",
    "    Bdata, Mdata =  (test_data['Class'].value_counts())\n",
    "    testshape = test_data.shape[0]\n",
    "    \n",
    "    l1 = str(\"The testing data consists of \" + str(testshape) + \" different diagnosis in which \" + str(Bdata) + \n",
    "          \" are Benign and \" + str(Mdata) + \" are Malignant\")\n",
    "    return l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to group data based on class label to compute the individual means and standard deviations of the independent features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouping(dataset):\n",
    "    \n",
    "    # Grouping of data is necessary in a Naive bayes classifier as we have to calculate the individual probability with respect\n",
    "    # to a feature in a particular class labelled label \n",
    "    grouped = dataset.groupby('Class')\n",
    "    B_data = grouped.get_group(2)\n",
    "    B_data = B_data.iloc[:, 0:9]\n",
    "    \n",
    "    M_data = grouped.get_group(4)\n",
    "    M_data = M_data.iloc[:, 0:9]\n",
    "    \n",
    "    return B_data, M_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(points):\n",
    "    \n",
    "    # The mean is defined as the sum of the datapoints or observations divided by the number observations or datapoints\n",
    "    return np.sum(points)/np.size(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MeanSet(data1,data2):\n",
    "    \n",
    "    B_mean_set = []\n",
    "    M_mean_set = []\n",
    "    \n",
    "    # To calculate the mean of every independent feature for both classes\n",
    "    for i in range(0,len(data1.columns)):\n",
    "        p = data1.iloc[:,i]\n",
    "        m = mean(p)\n",
    "        B_mean_set.append(m)\n",
    "        \n",
    "    for i in range(0,len(data2.columns)):\n",
    "        p = data2.iloc[:,i]\n",
    "        m = mean(p)\n",
    "        M_mean_set.append(m)\n",
    "        \n",
    "    return B_mean_set, M_mean_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard deviation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def st_dev(points, mean):\n",
    "    \n",
    "   # Standard deviation is defined as the square root of the sum of difference between the observations and their mean \n",
    "   # divided by the no.0f observations\n",
    "   variance = np.sum([(x - mean)**2 for x in points])/(np.size(points) - 1)\n",
    "   return np.sqrt(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SDset(data1, data2, mean1, mean2):\n",
    "    \n",
    "    B_sd_set = []\n",
    "    M_sd_set = []\n",
    "        \n",
    "    # To calculate the standard deviation of every independent feature for both classes\n",
    "    for i in range(0, len(data1.columns)):\n",
    "        p = data1.iloc[:,i]\n",
    "        sd = st_dev(p, mean1[i])\n",
    "        B_sd_set.append(sd)\n",
    "    \n",
    "    for i in range(0, len(data2.columns)):\n",
    "        p = data2.iloc[:,i]\n",
    "        sd = st_dev(p, mean2[i])\n",
    "        M_sd_set.append(sd)\n",
    "    \n",
    "    return B_sd_set, M_sd_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Guassian probability density function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "\n",
    "def probability(x, mean, sd):\n",
    "    \n",
    "    # This is the gaussian probability density function, which has the mathematical equation\n",
    "    # (1/sqrt(2*pi*(sd)^2)) * exp((-sum(xi-mean)^2)/2*(sd^2))\n",
    "    e = np.exp(-((x - mean)**2 / (2 * sd**2 )))\n",
    "    return (1 / (np.sqrt(2 * pi) * sd)) * e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to predict class labels for the given testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(testData, mean1, mean2, sd1, sd2):\n",
    "    \n",
    "    test_prob_set1 = []\n",
    "    test_prob_set2 = []\n",
    "    p1 = []\n",
    "    p2 = []\n",
    "    \n",
    "    # To predict the class labels for testing data\n",
    "    # We took two empty lists as we have two classes and we need to calculate the probabilities of a datapoint with two \n",
    "    # groups of data\n",
    "    for i in range(0, len(testData.index)):\n",
    "        for j in range(0, len(testData.columns)-1):\n",
    "            prob1 = probability(testData.iloc[i,j], mean1[j], sd1[j])\n",
    "            prob2 = probability(testData.iloc[i,j], mean2[j], sd2[j])\n",
    "            test_prob_set1.append(prob1)\n",
    "            test_prob_set2.append(prob2) \n",
    "            \n",
    "        # Multiply the independent probabilities to get the probability for that particular group of data\n",
    "        a = np.prod(test_prob_set1)\n",
    "        b = np.prod(test_prob_set2)\n",
    "        \n",
    "        # Then append the two prbabilities in two empty lists\n",
    "        p1.append(a)\n",
    "        p2.append(b)\n",
    "    \n",
    "    return p1, p2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification report metrics consists of Accuracy, Precision, Recall, F1-score and Confusion matrix to evaluate the preformance of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classification_report(testData, p, q):\n",
    "    \n",
    "    #Intialize the true positives, false positives, true negatives and the false negatives\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "\n",
    "    # Iterate through the p and q lists comparing the predicted labels with the actual ones and computing \n",
    "    # the TP, TN, FP and FN\n",
    "    for i in range(0, len(testData.index)):\n",
    "        if (p[i] == max(p[i], q[i]) and testData.iloc[i,9] == 2):\n",
    "            TP += 1\n",
    "        elif (q[i] == max(p[i], q[i]) and testData.iloc[i,9] == 4):\n",
    "            TN += 1\n",
    "        elif (q[i] == max(p[i], q[i]) and testData.iloc[i,9] == 2):   \n",
    "            FN += 1\n",
    "        elif (p[i] == max(p[i], q[i]) and testData.iloc[i,9] == 4):\n",
    "            FP += 1\n",
    "            \n",
    "    # Accuracy is the measure of many correct predictions the model made        \n",
    "    A = (TP + TN)/(TP + TN + FP + FN) * 100.0\n",
    "    \n",
    "    # precision expresses the proportion of the data points our model says was relevant actually were relevant.\n",
    "    P1 = (TP)/(TP + FP) * 100.0\n",
    "    P2 = (TN)/(TN + FN) * 100.0\n",
    "    \n",
    "    # Recall expresses the ability to find all relevant instances in a dataset\n",
    "    R1 = (TP)/(TP + FN) * 100.0\n",
    "    R2 = (TN)/(TN + FP) * 100.0\n",
    "    \n",
    "    # Harmonic mean of recall and precision \n",
    "    F1 = (2*P1*R1)/(R1 + P1)\n",
    "    F2 = (2*P2*R2)/(P2 + R2)\n",
    "    \n",
    "    # A matrix to represent all types of predictions \n",
    "    CM = np.array([[TP, FP],[FN, TN]])\n",
    "    \n",
    "    return A, P1, P2, R1, R2, F1, F2, CM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A main() function to simplify the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # Reading the data file and converting it into a dataframe\n",
    "    data = pd.read_excel(r\"C:\\Users\\sriva\\OneDrive\\Desktop\\Python_for_ML_project_dataset\\breast-cancer-wisconsin.xlsx\")\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Processing the data\n",
    "    m = dataClassification(data)\n",
    "    splitRatio = 0.75\n",
    "    df1 = trainingDataset(data, splitRatio)\n",
    "    df2 = testingData(data, splitRatio)\n",
    "    l = DataDivision(df1, df2)\n",
    "    t = testdataclassification(df2)\n",
    "    \n",
    "    # Parameter calculation\n",
    "    B_data, M_data = grouping(df1)\n",
    "    B_mean_set, M_mean_set = MeanSet(B_data,M_data)\n",
    "    B_sd_set, M_sd_set = SDset(B_data, M_data, B_mean_set, M_mean_set)\n",
    "    \n",
    "    # Predictions\n",
    "    p1, p2 = prediction(df2, B_mean_set, M_mean_set, B_sd_set, M_sd_set)\n",
    "    \n",
    "    # Model evaluation\n",
    "    Acc, PrecisionB, PrecisionM, RecallB, RecallM, F1_scoreB, F1_scoreM, cm = Classification_report(df2, p1, p2)\n",
    "    \n",
    "    print(m)\n",
    "    print(l)\n",
    "    print(t)\n",
    "    print(\"\\n\" + \"The Accuracy of the NaiveBayes model is: \"+ str(Acc) + \"%\")\n",
    "    print(\"\\n\" + \"The Precision of the NaiveBayes model is: \"+ str((PrecisionB + PrecisionM)/2) + \"%\")\n",
    "    print(\"\\n\" + \"The Recall of the NaiveBayes model is: \"+ str((RecallB + RecallM)/2) + \"%\")\n",
    "    print(\"\\n\" + \"The F1 score of the NaiveBayes model is: \"+ str((F1_scoreB + F1_scoreM)/2) + \"%\")\n",
    "    print(\"\\n\" + \"The Confusion matrix of the NaiveBayes model is: \" + \"\\n\" + str(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
